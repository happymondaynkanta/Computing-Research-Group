{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input shape and number of classes\n",
    "input_shape = (224, 224, 3)\n",
    "num_classes = 1\n",
    "dataset_dir=r'E:\\2023 OBU-CDUT\\2023 Semester 1\\crc_skin_data'\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The block of code sets up data augmentation for training images using the ImageDataGenerator class from the Keras library. Data augmentation is a technique commonly used in deep learning to artificially increase the size of the training dataset by applying various transformations to the existing images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_datagen = ImageDataGenerator(: This line creates an instance of the ImageDataGenerator class and assigns it to the variable train_datagen. This object will be used to perform data augmentation on the training images.\n",
    "\n",
    "### rescale=1./255,: This parameter rescales the pixel values of the images by dividing them by 255. This normalization step brings the pixel values to the range of [0, 1], which is commonly done to ensure the input values are within a suitable range for training.\n",
    "\n",
    "### shear_range=0.2,: This parameter specifies the range for applying shear transformations to the images. Shear transformations slant the image in a certain direction, creating a distorted effect.\n",
    "\n",
    "### zoom_range=0.2,: This parameter specifies the range for applying zoom transformations to the images. Zoom transformations change the scale of the image, either making it larger or smaller.\n",
    "\n",
    "### horizontal_flip=True): This parameter enables horizontal flipping of the images. It randomly flips the images horizontally, creating a mirror image effect. This augmentation technique is useful when there is no specific horizontal orientation in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_datagen = ImageDataGenerator(rescale=1./255): This line creates another instance of the ImageDataGenerator class and assigns it to the variable test_datagen. This object is used for preprocessing the test/validation images, but it doesn't apply any data augmentation techniques except for the rescaling of pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test data should not be augmented\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code generates the training dataset using the flow_from_directory method of the train_datagen object. It prepares the data to be fed into the model during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_generator = train_datagen.flow_from_directory(: This line calls the flow_from_directory method of the train_datagen object to generate the training dataset iterator and assigns it to the variable train_generator. This iterator will generate batches of augmented images along with their corresponding labels.\n",
    "\n",
    "### os.path.join(dataset_dir, 'train'): This line uses the os.path.join function to construct the directory path for the training dataset. It combines the dataset_dir (the root directory where the dataset is located) with the 'train' subdirectory, which typically contains the training images.\n",
    "\n",
    "### target_size=input_shape[:2],: This parameter specifies the target size to which the images should be resized. It uses the input_shape variable, which represents the desired input shape of the model, and takes the first two elements of the shape (width and height). The images in the training dataset will be resized to this target size.\n",
    "\n",
    "### batch_size=batch_size,: This parameter specifies the number of samples in each batch of the training dataset. The batch_size variable represents the desired batch size for training.\n",
    "\n",
    "### class_mode='binary': This parameter specifies the type of labels to generate for the training dataset. In this case, 'binary' indicates that the labels are two classes represented '0 or 1' \n",
    "\n",
    "### ): This closing parenthesis ends the flow_from_directory method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate the train dataset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'train'),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validation_generator = test_datagen.flow_from_directory(: This line calls the flow_from_directory method of the train_datagen object to generate the training dataset iterator and assigns it to the variable train_generator. This iterator will generate batches of augmented images along with their corresponding labels.\n",
    "\n",
    "### os.path.join(dataset_dir, 'train'): This line uses the os.path.join function to construct the directory path for the training dataset. It combines the dataset_dir (the root directory where the dataset is located) with the 'train' subdirectory, which typically contains the training images.\n",
    "\n",
    "### target_size=input_shape[:2],: This parameter specifies the target size to which the images should be resized. It uses the input_shape variable, which represents the desired input shape of the model, and takes the first two elements of the shape (width and height). The images in the training dataset will be resized to this target size.\n",
    "\n",
    "### batch_size=batch_size,: This parameter specifies the number of samples in each batch of the training dataset. The batch_size variable represents the desired batch size for training.\n",
    "\n",
    "### class_mode='binary': This parameter specifies the type of labels to generate for the training dataset. In this case, 'binary' indicates that the labels are two classes represented '0 or 1' \n",
    "\n",
    "### ): This closing parenthesis ends the flow_from_directory method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate the validation dataset\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'train'),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test_generator = test_datagen.flow_from_directory(: This line calls the flow_from_directory method of the train_datagen object to generate the training dataset iterator and assigns it to the variable train_generator. This iterator will generate batches of augmented images along with their corresponding labels.\n",
    "\n",
    "### os.path.join(dataset_dir, 'train'): This line uses the os.path.join function to construct the directory path for the training dataset. It combines the dataset_dir (the root directory where the dataset is located) with the 'train' subdirectory, which typically contains the training images.\n",
    "\n",
    "### target_size=input_shape[:2],: This parameter specifies the target size to which the images should be resized. It uses the input_shape variable, which represents the desired input shape of the model, and takes the first two elements of the shape (width and height). The images in the training dataset will be resized to this target size.\n",
    "\n",
    "### batch_size=batch_size,: This parameter specifies the number of samples in each batch of the training dataset. The batch_size variable represents the desired batch size for training.\n",
    "\n",
    "### class_mode='binary': This parameter specifies the type of labels to generate for the training dataset. In this case, 'binary' indicates that the labels are two classes represented '0 or 1' \n",
    "\n",
    "### ): This closing parenthesis ends the flow_from_directory method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate the test dataset\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'test'),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def residual_block(inputs, num_filters):: This line defines a function named residual_block that takes two parameters: inputs (the input tensor) and num_filters (the number of filters in the convolutional layers).\n",
    "\n",
    "### x = Conv2D(num_filters, kernel_size=(3, 3), padding='same')(inputs): This line applies a 2D convolutional layer to the inputs tensor with num_filters filters, each with a kernel size of 3x3 and same padding. The result is stored in the x variable.\n",
    "\n",
    "### x = BatchNormalization()(x): This line applies batch normalization to the x tensor, which normalizes the activations and helps with training stability and speed.\n",
    "\n",
    "### x = Activation('relu')(x): This line applies the ReLU activation function to the x tensor, introducing non-linearity to the model.\n",
    "\n",
    "### x = Conv2D(num_filters, kernel_size=(3, 3), padding='same')(x): This line applies another 2D convolutional layer to the x tensor with num_filters filters and 3x3 kernel size, preserving the spatial dimensions with same padding.\n",
    "\n",
    "### x = BatchNormalization(a)(x): This line applies batch normalization to the x tensor, similar to line 4.\n",
    "\n",
    "### if inputs.shape[-1] != num_filters:: This line checks if the number of channels in the inputs tensor is not equal to num_filters. This condition is used to determine whether a skip connection is needed or not.\n",
    "\n",
    "### shortcut = Conv2D(num_filters, kernel_size=(1, 1), padding='same')(inputs): This line applies a 1x1 convolutional layer to the inputs tensor to match the number of filters (num_filters) of the x tensor. This operation is used when the skip connection is required.\n",
    "\n",
    "### shortcut = BatchNormalization()(shortcut): This line applies batch normalization to the shortcut tensor, similar to line 4.\n",
    "\n",
    "### shortcut = inputs: This line assigns the inputs tensor to the shortcut variable when the skip connection is not needed.\n",
    "\n",
    "### x = Add()([x, shortcut]): This line adds the x tensor and the shortcut tensor element-wise, implementing the skip connection.\n",
    "\n",
    "### x = Activation('relu')(x): This line applies the ReLU activation function to the resulting tensor x.\n",
    "\n",
    "### return x: This line returns the output tensor x from the residual_block function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the residual block\n",
    "def residual_block(inputs, num_filters):\n",
    "    # Convolutional layers\n",
    "    x = Conv2D(num_filters, kernel_size=(3, 3), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(num_filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Skip connection\n",
    "    if inputs.shape[-1] != num_filters:\n",
    "        shortcut = Conv2D(num_filters, kernel_size=(1, 1), padding='same')(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    else:\n",
    "        shortcut = inputs\n",
    "    \n",
    "    # Add skip connection\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def ResNet(input_shape, num_classes):: This line defines a function named ResNet that takes two parameters: input_shape (the shape of the input tensor) and num_classes (the number of classes for classification).\n",
    "\n",
    "### inputs = Input(shape=input_shape): This line creates a Keras input tensor with the specified input_shape and assigns it to the inputs variable.\n",
    "\n",
    "### x = Conv2D(64, kernel_size=(7, 7), padding='same')(inputs): This line applies a 2D convolutional layer to the inputs tensor with 64 filters and a larger 7x7 kernel size, preserving spatial dimensions.\n",
    "\n",
    "### x = BatchNormalization()(x): This line applies batch normalization to the x tensor.\n",
    "\n",
    "### x = Activation('relu')(x): This line applies the ReLU activation function to the x tensor.\n",
    "\n",
    "### 34-39. x = residual_block(x, num_filters): These lines apply the residual_block function multiple times, passing the x tensor and the specified num_filters for each block. This builds the residual part of the ResNet model.\n",
    "\n",
    "### x = GlobalAveragePooling2D()(x): This line applies global average pooling to the x tensor, reducing the spatial dimensions to a vector.\n",
    "\n",
    "### x = Dense(512, activation='relu')(x): This line applies a fully connected layer to the x tensor with 512 units and applies the ReLU activation function.\n",
    "\n",
    "### outputs = Dense(num_classes, activation='softmax')(x): This line applies a fully connected layer to the x tensor with num_classes units (output classes) and applies the softmax activation function to obtain class probabilities.\n",
    "\n",
    "### model = Model(inputs=inputs, outputs=outputs): This line creates a Keras Model object by specifying the inputs tensor as the model's input and the outputs tensor as the model's output.\n",
    "\n",
    "### return model: This line returns the created model.\n",
    "\n",
    "### model = ResNet(input_shape, num_classes): This line creates an instance of the ResNet model by calling the ResNet function with the specified input_shape and num_classes arguments, and assigns it to the model variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "# Define the ResNet-like model\n",
    "def ResNet(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Initial convolutional layer\n",
    "    x = Conv2D(64, kernel_size=(7, 7), padding='valid')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(3,3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # Residual blocks\n",
    "    x = residual_block(x, 64) # 2 conv layers\n",
    "    x = residual_block(x, 64) # 2 conv layers\n",
    "    \n",
    "    x = residual_block(x, 128) # 2 conv layers\n",
    "    x = residual_block(x, 128) # 2 conv layers\n",
    "    \n",
    "    x = residual_block(x, 256) # 2 conv layers\n",
    "    x = residual_block(x, 256) # 2 conv layers\n",
    "    \n",
    "    # Global average pooling and fully connected layer\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(num_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ResNet model\n",
    "model = ResNet(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.optimizers import Adam\n",
    "#optimizer=Adam(lr=0.001)\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 218, 218, 64) 9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 218, 218, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 72, 72, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 72, 72, 64)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 72, 72, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 72, 72, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 72, 72, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 72, 72, 64)   36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 72, 72, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 72, 72, 64)   0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 72, 72, 64)   0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 72, 72, 64)   36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 72, 72, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 72, 72, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 72, 72, 64)   36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 72, 72, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 72, 72, 64)   0           batch_normalization_19[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 72, 72, 64)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 72, 72, 128)  73856       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 72, 72, 128)  512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 72, 72, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 72, 72, 128)  147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 72, 72, 128)  8320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 72, 72, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 72, 72, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 72, 72, 128)  0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 72, 72, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 72, 72, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 72, 72, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 72, 72, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 72, 72, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 72, 72, 128)  512         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 72, 72, 128)  0           batch_normalization_24[0][0]     \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 72, 72, 128)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 72, 72, 256)  295168      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 72, 72, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 72, 72, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 72, 72, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 72, 72, 256)  33024       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 72, 72, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 72, 72, 256)  1024        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 72, 72, 256)  0           batch_normalization_26[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 72, 72, 256)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 72, 72, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 72, 72, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 72, 72, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 72, 72, 256)  590080      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 72, 72, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 72, 72, 256)  0           batch_normalization_29[0][0]     \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 72, 72, 256)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 256)          0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          131584      global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            513         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,921,601\n",
      "Trainable params: 2,917,121\n",
      "Non-trainable params: 4,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 179s 1s/step - loss: 0.6876 - accuracy: 0.6680 - val_loss: 0.7613 - val_accuracy: 0.3300\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history=model.fit(train_generator,epochs=1,validation_data=validation_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 6s 245ms/step - loss: 0.7591 - accuracy: 0.3200\n",
      "Test loss: 0.75913405418396\n",
      "Test accuracy: 0.3199999928474426\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from keras import backend as K: This line imports the backend module from the Keras library and assigns it the alias K. The backend module provides low-level operations and functions for working with tensors, which are multi-dimensional arrays used for deep learning computations.\n",
    "\n",
    "### import gc: This line imports the gc module, which stands for garbage collector. The garbage collector is responsible for freeing up memory by reclaiming objects that are no longer in use.\n",
    "\n",
    "### K.clear_session(): This line clears the Keras session. A session in Keras is a way to organize and execute a sequence of operations, such as building and training a neural network model. Clearing the session releases any resources associated with the current session, including tensors and variables.\n",
    "\n",
    "### gc.collect(): This line triggers the garbage collector to collect and free any unused memory. Calling gc.collect() helps to ensure that any unreferenced objects are properly cleaned up and their memory is reclaimed.\n",
    "\n",
    "### del model: This line deletes the variable model. It removes the reference to the model object and frees up the memory it was occupying. This step is useful when you want to release the resources associated with a model that is no longer needed.\n",
    "\n",
    "### Overall, this code is a common practice in deep learning to clear the session, perform garbage collection, and delete the model to manage memory usage and avoid potential memory leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import gc\n",
    "\n",
    "K.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from numba import cuda: This line imports the cuda module from the numba library. The cuda module provides an interface to interact with NVIDIA GPUs for parallel computing tasks. It allows you to utilize the power of the GPU to accelerate certain computations.\n",
    "\n",
    "### cuda.select_device(0): This line selects the CUDA device with index 0. CUDA is a parallel computing platform and API model created by NVIDIA that allows developers to perform general-purpose computing on GPUs. By calling select_device(0), the code specifies that the GPU with index 0 should be used for computation. If you have multiple GPUs, you can change the index to select a different GPU.\n",
    "\n",
    "### cuda.close(): This line closes the CUDA context. When you're done using the GPU resources, it's good practice to close the CUDA context to release any associated memory and resources. This ensures that the GPU resources are freed up and can be used by other applications or processes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need to install numba using \"pip install numba\"\n",
    "from numba import cuda\n",
    "\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
