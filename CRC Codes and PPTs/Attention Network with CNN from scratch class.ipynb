{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Concatenate, Flatten, Dropout\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "dataset_dir = r'E:\\2023 OBU-CDUT\\2023 Semester 1\\crc_skin_data'\n",
    "batch_size = 4\n",
    "num_classes =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)  # 20% of the data will be used for validation\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'train'),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training')  # Use the training subset of the data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'train'),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation')  # Use the validation subset of the data\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(dataset_dir, 'test'),\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Rest of the code remains the same...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, channels):\n",
    "        super(Attention, self).__init__()\n",
    "        self.channels=channels\n",
    "        self.conv1= Conv2D(self.channels, kernel_size=1, strides=1, padding='valid')\n",
    "        self.conv2= Conv2D(self.channels, kernel_size=1, strides=1, padding='valid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.nn.softmax(x, axis=-1) # height x width x Channel (224x224x3)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Attention model\n",
    "def attention_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    conv1 = Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(256, kernel_size=(5, 5), activation='relu')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(384, kernel_size=(3, 3), activation='relu')(pool2)\n",
    "    conv4 = Conv2D(384, kernel_size=(3, 3), activation='relu')(conv3)\n",
    "    conv5 = Conv2D(256, kernel_size=(3, 3), activation='relu')(conv4)\n",
    "    pool3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv5)\n",
    "    \n",
    "    # Attention layer\n",
    "    attention = Attention(channels=256)(pool3)\n",
    "    \n",
    "    # Apply attention to the feature map\n",
    "    attention_maps = tf.multiply(pool3, attention)\n",
    "    concatenate_maps = Concatenate()([pool3, attention_maps])\n",
    "    \n",
    "    flatten = Flatten()( concatenate_maps)\n",
    "    \n",
    "    # Fully connected layers\n",
    "    fc1 = Dense(4096, activation='relu')(flatten)\n",
    "    dropout1 = Dropout(0.5)(fc1)\n",
    "    fc2 = Dense(4096, activation='relu')(dropout1)\n",
    "    dropout2 = Dropout(0.5)(fc2)\n",
    "    output = Dense(num_classes, activation='softmax')(dropout2)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Attention model\n",
    "\n",
    "\n",
    "model = attention_model(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history=model.fit(train_generator,epochs=2,validation_data=validation_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import gc\n",
    "\n",
    "K.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need to install numba using \"pip install numba\"\n",
    "from numba import cuda\n",
    "\n",
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
